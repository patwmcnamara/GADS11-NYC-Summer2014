{
 "metadata": {
  "name": "",
  "signature": "sha256:568cc38f28bb065be47e5d8c46fc61d9a4aad51aa9c3e1d914d4032a11afc84a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Explaining Titanic Hypothesis with Decision Trees\n",
      "####From book \"Learning scikit-learn: machine learning in Python\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we must load the dataset. We assume it is located in the data/titanic.csv file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import numpy as np\n",
      "with open('data/titanic.csv', 'r') as csvfile:\n",
      "    titanic_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Header contains feature names\n",
      "    row = titanic_reader.next()\n",
      "    feature_names = np.array(row)\n",
      "    \n",
      "    # Load dataset, and target classes\n",
      "    titanic_X, titanic_y = [], []\n",
      "    for row in titanic_reader:  \n",
      "        titanic_X.append(row)\n",
      "        titanic_y.append(row[0]) # The target value is \"survived\"\n",
      "    \n",
      "    titanic_X = np.array(titanic_X)\n",
      "    titanic_y = np.array(titanic_y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inspecting last row object\n",
      "row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "['0',\n",
        " '3',\n",
        " 'Dooley, Mr. Patrick',\n",
        " 'male',\n",
        " '32',\n",
        " '0',\n",
        " '0',\n",
        " '370376',\n",
        " '7.75',\n",
        " '',\n",
        " 'Q']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inspecting \n",
      "print feature_names, titanic_X[0], titanic_y[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['survived' 'pclass' 'name' 'sex' 'age' 'sibsp' 'parch' 'ticket' 'fare'\n",
        " 'cabin' 'embarked'] ['0' '3' 'Braund, Mr. Owen Harris' 'male' '22' '1' '0' 'A/5 21171' '7.25'\n",
        " '' 'S'] 0\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Keep only class (1st,2nd,3rd), age (float), and sex (masc, fem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We keep the class, age and sex variables\n",
      "titanic_X = titanic_X[:, [1, 4, 3]]\n",
      "feature_names = feature_names[[1, 4, 3]]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_names\n",
      "print titanic_X[12], titanic_y[12]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['pclass' 'age' 'sex']\n",
        "['3' '20' 'male'] 0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Solve missing values ('NA') for the 'age' feature. Solution: use the mean value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We have missing values for age\n",
      "# Assign the mean value\n",
      "ages = titanic_X[:, 1]\n",
      "mean_age = np.mean(titanic_X[ages != '', 1].astype(np.float))\n",
      "titanic_X[titanic_X[:, 1] == '', 1] = mean_age\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_names\n",
      "print titanic_X[5], titanic_y[5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['pclass' 'age' 'sex']\n",
        "['3' '29.6991176471' 'male'] 0\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Class and sex are categorical classes. Sex can be converted to a binary value (0=female,1=male):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Encode sex \n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(titanic_X[:, 2])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
      "print \"Integer classes:\", integer_classes\n",
      "t = label_encoder.transform(titanic_X[:, 2])\n",
      "titanic_X[:, 2] = t\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['female' 'male']\n",
        "Integer classes: [0 1]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_names\n",
      "print titanic_X[5], titanic_y[5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['pclass' 'age' 'sex']\n",
        "['3' '29.6991176471' '1'] 0\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we have to convert the class. Since we have three different classes, we cannot convert to binary values (and using 0/1/2 values would imply an order, something we do not want). We use OneHotEncoder to get three different attributes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(titanic_X[:, 0])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_).reshape(3, 1)\n",
      "print \"Integer classes:\", integer_classes\n",
      "enc = OneHotEncoder()\n",
      "one_hot_encoder = enc.fit(integer_classes)\n",
      "# First, convert clases to 0-(N-1) integers using label_encoder\n",
      "num_of_rows = titanic_X.shape[0]\n",
      "t = label_encoder.transform(titanic_X[:, 0]).reshape(num_of_rows, 1)\n",
      "# Second, create a sparse matrix with three columns, each one indicating if the instance belongs to the class\n",
      "new_features = one_hot_encoder.transform(t)\n",
      "# Add the new features to titanix_X\n",
      "titanic_X = np.concatenate([titanic_X, new_features.toarray()], axis = 1)\n",
      "#Eliminate converted columns\n",
      "titanic_X = np.delete(titanic_X, [0], 1)\n",
      "# Update feature names\n",
      "feature_names = ['age', 'sex', 'first_class', 'second_class', 'third_class']\n",
      "# Convert to numerical values\n",
      "titanic_X = titanic_X.astype(float)\n",
      "titanic_y = titanic_y.astype(float)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['1' '2' '3']\n",
        "Integer classes: [[0]\n",
        " [1]\n",
        " [2]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_names\n",
      "print titanic_X[0], titanic_y[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['age', 'sex', 'first_class', 'second_class', 'third_class']\n",
        "[ 22.   1.   0.   0.   1.] 0.0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Separate training and test sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.25, random_state=33)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Decision Trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit a decision tree with the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
      "clf = clf.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Show the built tree, using pydot\n",
      "import pydot,StringIO\n",
      "dot_data = StringIO.StringIO() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree.export_graphviz(clf, out_file=dot_data, feature_names=['age','sex','1st_class','2nd_class','3rd_class']) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "<StringIO.StringIO instance at 0x108e48b00>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dot_data.getvalue()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "'digraph Tree {\\n0 [label=\"sex <= 0.5000\\\\nentropy = 0.957149056269\\\\nsamples = 668\", shape=\"box\"] ;\\n1 [label=\"3rd_class <= 0.5000\\\\nentropy = 0.842527857585\\\\nsamples = 229\", shape=\"box\"] ;\\n0 -> 1 ;\\n2 [label=\"age <= 23.5000\\\\nentropy = 0.318855418521\\\\nsamples = 121\", shape=\"box\"] ;\\n1 -> 2 ;\\n3 [label=\"entropy = 0.0000\\\\nsamples = 33\\\\nvalue = [  0.  33.]\", shape=\"box\"] ;\\n2 -> 3 ;\\n4 [label=\"entropy = 0.4006\\\\nsamples = 88\\\\nvalue = [  7.  81.]\", shape=\"box\"] ;\\n2 -> 4 ;\\n5 [label=\"age <= 38.5000\\\\nentropy = 0.999752610166\\\\nsamples = 108\", shape=\"box\"] ;\\n1 -> 5 ;\\n6 [label=\"entropy = 0.9982\\\\nsamples = 99\\\\nvalue = [ 47.  52.]\", shape=\"box\"] ;\\n5 -> 6 ;\\n7 [label=\"entropy = 0.5033\\\\nsamples = 9\\\\nvalue = [ 8.  1.]\", shape=\"box\"] ;\\n5 -> 7 ;\\n8 [label=\"age <= 8.5000\\\\nentropy = 0.713651451474\\\\nsamples = 439\", shape=\"box\"] ;\\n0 -> 8 ;\\n9 [label=\"3rd_class <= 0.5000\\\\nentropy = 0.899743758698\\\\nsamples = 19\", shape=\"box\"] ;\\n8 -> 9 ;\\n10 [label=\"entropy = 0.0000\\\\nsamples = 9\\\\nvalue = [ 0.  9.]\", shape=\"box\"] ;\\n9 -> 10 ;\\n11 [label=\"entropy = 0.9710\\\\nsamples = 10\\\\nvalue = [ 6.  4.]\", shape=\"box\"] ;\\n9 -> 11 ;\\n12 [label=\"1st_class <= 0.5000\\\\nentropy = 0.666345599469\\\\nsamples = 420\", shape=\"box\"] ;\\n8 -> 12 ;\\n13 [label=\"entropy = 0.5272\\\\nsamples = 327\\\\nvalue = [ 288.   39.]\", shape=\"box\"] ;\\n12 -> 13 ;\\n14 [label=\"entropy = 0.9472\\\\nsamples = 93\\\\nvalue = [ 59.  34.]\", shape=\"box\"] ;\\n12 -> 14 ;\\n}'"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pydot.graph_from_dot_data(dot_data.getvalue())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'dot_parser' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-18-1dacaaf9f39c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pydot.pyc\u001b[0m in \u001b[0;36mgraph_from_dot_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \"\"\"\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdot_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'dot_parser' is not defined"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
      "graph.write_png('titanic.png') \n",
      "from IPython.core.display import Image \n",
      "Image(filename='titanic.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree.export_graphviz(clf, out_file=dot_data, feature_names=['age','sex','1st_class','2nd_class','3rd_class']) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Measure Accuracy, precision, recall, f1 in the training set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
      "    y_pred=clf.predict(X)   \n",
      "    if show_accuracy:\n",
      "        print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\"\n",
      "\n",
      "    if show_classification_report:\n",
      "        print \"Classification report\"\n",
      "        print metrics.classification_report(y,y_pred),\"\\n\"\n",
      "        \n",
      "    if show_confusion_matrix:\n",
      "        print \"Confusion matrix\"\n",
      "        print metrics.confusion_matrix(y,y_pred),\"\\n\"\n",
      "        \n",
      "measure_performance(X_train,y_train,clf, show_classification_report=True, show_confusion_matrix=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform leave-one-out cross validation to better measure performance, reducing variance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, LeaveOneOut\n",
      "from sklearn import metrics\n",
      "from scipy.stats import sem\n",
      "\n",
      "def loo_cv(X_train,y_train,clf):\n",
      "    # Perform Leave-One-Out cross validation\n",
      "    # We are preforming 1313 classifications!\n",
      "    loo = LeaveOneOut(X_train[:].shape[0])\n",
      "    scores=np.zeros(X_train[:].shape[0])\n",
      "    for train_index,test_index in loo:\n",
      "        X_train_cv, X_test_cv= X_train[train_index], X_train[test_index]\n",
      "        y_train_cv, y_test_cv= y_train[train_index], y_train[test_index]\n",
      "        clf = clf.fit(X_train_cv,y_train_cv)\n",
      "        y_pred=clf.predict(X_test_cv)\n",
      "        scores[test_index]=metrics.accuracy_score(y_test_cv.astype(int), y_pred.astype(int))\n",
      "    print (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#LeaveOneOut?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loo_cv(X_train, y_train,clf)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean score: 0.802 (+/-0.015)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try to improve performance using Random Forests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_estimators=10,random_state=33)\n",
      "clf = clf.fit(X_train,y_train)\n",
      "loo_cv(X_train,y_train,clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean score: 0.798 (+/-0.016)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To evaluate performance on future data, evaluate on the training set and test on the evaluation set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attempt 1\n",
      "clf_dt=tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
      "clf_dt.fit(X_train,y_train)\n",
      "measure_performance(X_test,y_test,clf_dt)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'measure_performance' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-f907e1d6c556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmeasure_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'measure_performance' is not defined"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tree.DecisionTreeClassifier?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attempt 2\n",
      "clf_dt=tree.DecisionTreeClassifier(criterion='gini', max_depth=3,min_samples_leaf=20)\n",
      "clf_dt.fit(X_train,y_train)\n",
      "measure_performance(X_test,y_test,clf_dt)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "A New Measure: the ROC and Area Under a Curve (AUC)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way we can score a binary classification is by plotting the reciever operating characteristic and determining the value of the area under curve (AUC). Like above, our goal is to see an AUC as close to 1 as possible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Syntax for roc_curve is roc_curve(actual, prediction, [pos_label if it's not 1])\n",
      "predictions = [p[1] for p in clf_dt.predict_proba(X_train)]\n",
      "fpr_p, tpr_p, thresholds_p = metrics.roc_curve(y_train,predictions)\n",
      "\n",
      "fig = plt.figure()\n",
      "fig.set_figwidth(10)\n",
      "fig.suptitle('AUC for Decision Tree Classifier Predicting Titanic Survivors')\n",
      "\n",
      "ax1 = plt.subplot(1, 2, 1)\n",
      "ax1.set_xlabel('false positive rate')\n",
      "ax1.set_ylabel('true positive rate')\n",
      "ax1.plot(fpr_p, tpr_p)\n",
      "\n",
      "fpr, tpr, thresholds = metrics.roc_curve(y_train,clf_dt.predict(X_train))\n",
      "ax2 = plt.subplot(1, 2, 2)\n",
      "ax2.set_xlabel('false positive rate')\n",
      "ax2.set_ylabel('true positive rate')\n",
      "ax2.plot(fpr, tpr)\n",
      "\n",
      "\n",
      "print \"False-positive rate:\", fpr\n",
      "print \"True-positive rate: \", tpr\n",
      "print \"Thresholds:         \", thresholds\n",
      "\n",
      "print fig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random seed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "import random\n",
      "\n",
      "random.seed( 100 )\n",
      "print \"Random number with seed 10 : \", random.random()\n",
      "\n",
      "# It will generate same random number\n",
      "random.seed( 100 )\n",
      "print \"Random number with seed 10 : \", random.random()\n",
      "\n",
      "# It will generate same random number\n",
      "random.seed( 100 )\n",
      "print \"Random number with seed 10 : \", random.random()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Reading this**\n",
      "\n",
      "When we consider a positive (1) instance matching a postive (1) test, then that's considered a *true positive*; otherwise, it is considered a *false negative*. If the instance is a negative and it is classified as negative, we consider that a *true negative*; otherwise, a *false positive*. \n",
      "\n",
      "The True Positive Rate (tpr) is calculated using true positives / all positives, while the False Positive Rate (fpr) is calculated using false negatives / all negatives.\n",
      "\n",
      "We can find *sensitivity* as (True Negatives) / (False Positives + True Negatives).\n",
      "\n",
      "The goal for an AUC curve is to be as close to point(0, 1) as possible, which means 0 false positive, and all true positives. \n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Assignment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Continue plugging away at the titanic data set to see if you can come up with a **better** predictor than what we built above using either DT, RF, or naive bayes!\n",
      "\n",
      "You will want to spend **MOST** of your time continuing to manipulate the data set, creating new features, and understanding the relationship between these features and how they contribute to predicting the \"survived\" data.\n",
      "\n",
      "Please work with a partner and pair program."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}