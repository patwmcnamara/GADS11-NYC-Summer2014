{
 "metadata": {
  "name": "",
  "signature": "sha256:1521ce827ea28af7afc658584af01aea0f4c85ac6c006e381098017a4dc874be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "import warnings\n",
      "warnings.simplefilter(\"ignore\", DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If running for the first time set 'fresh'=1 for a fresh run\n",
      "# otherwise pre-load the data from file\n",
      "# takes a few mins to run the first time\n",
      "fresh = 0\n",
      "if fresh == 1:\n",
      "    df = pd.read_csv('baseball.csv')\n",
      "else:\n",
      "    df = pd.read_pickle('df_baseball.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'df_baseball.pkl'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-66-050023790907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baseball.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_baseball.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'df_baseball.pkl'"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# All the features we have to work with\n",
      "#1 \"playerID\" - Unique number \n",
      "#2 \"lahmanID\" - Unique code\n",
      "#3 \"managerID\" - Manager ID\n",
      "#4 \"hofID\" - Hall of fame ID\n",
      "#5 \"birthYear\"\n",
      "#6 \"birthMonth\"\n",
      "#7 \"birthDay\"\n",
      "#8 \"birthCountry\"\n",
      "#9 \"birthState\"\n",
      "#10 \"birthCity\"\n",
      "#11 \"deathYear\"\n",
      "#12 \"deathMonth\"\n",
      "#13 \"deathDay\"\n",
      "#14 \"deathCountry\"\n",
      "#15 \"deathState\"\n",
      "#16 \"deathCity\"\n",
      "#17 \"nameFirst\"\n",
      "#18 \"nameLast\"\n",
      "#19 \"nameNote\" - Indicates changed name or played under diff name\n",
      "#20 \"nameGiven\"\n",
      "#21 \"nameNick\" - Nick name\n",
      "#22 \"weight\" - weight in poinds\n",
      "#23 \"height\" - height in inches\n",
      "#24 \"bats\" - left, right, or both\n",
      "#25 \"throws\" - left or right\n",
      "#26 \"debut\" - date of first major league appearance\n",
      "#27 \"finalGame\" - date of last ....\n",
      "#28 \"college\" - College attended\n",
      "#29 \"lahman40ID\" - lahman id 4.0\n",
      "#30 \"lahman45ID\" - lahman id 4.5\n",
      "#31 \"retroID\" - retrosheet id\n",
      "#32 \"holtzID\" - Hotlz almanac ID\n",
      "#33 \"bbrefID\" - Baseball reference website ID\n",
      "#34 \"deathDate\"\n",
      "#35 \"birthDate\"\n",
      "#36 \"yearID\" - year for data\n",
      "#37 \"teamID\" - team\n",
      "#38 \"lgID\" - league\n",
      "#39 \"stint\" - order of appearances within a season\n",
      "#40 \"G\" - games\n",
      "#41 \"G_batting\" - game as batter\n",
      "#42 \"AB\" - at bats\n",
      "#43 \"R\" - runs\n",
      "#44 \"H\" - hits\n",
      "#45 \"X2B\" - doubles \n",
      "#46 \"X3B\" - triples\n",
      "#47 \"HR\" - homerunes\n",
      "#48 \"RBI\" - runs batted in\n",
      "#49 \"SB\" - stolen bases\n",
      "#50 \"CS\" - caught stealing\n",
      "#51 \"BB\" - base on balls\n",
      "#52 \"SO\" - strikeouts\n",
      "#53 \"IBB\" - intentional walks\n",
      "#54 \"HBP\" - hit by pitch\n",
      "#55 \"SH\" - sacrifice hits\n",
      "#56 \"SF\" - sacrifice flies\n",
      "#57 \"GIDP\" - grounded into double plays\n",
      "#58 \"G_old\" - old verison of games\n",
      "#59 \"salary\" - salary that year"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1 playerID       Player ID code\n",
      "#2 yearID         Year\n",
      "#3 stint          player's stint (order of appearances within a season)\n",
      "#4 teamID         Team\n",
      "#5 lgID           League\n",
      "#6 W              Wins\n",
      "#7 L              Losses\n",
      "#8 G              Games\n",
      "#9 GS             Games Started\n",
      "#10 CG             Complete Games \n",
      "#11 SHO            Shutouts\n",
      "#12 SV             Saves\n",
      "#13 IPOuts         Outs Pitched (innings pitched x 3)\n",
      "#14 H              Hits\n",
      "#15 ER             Earned Runs\n",
      "#16 HR             Homeruns\n",
      "#17 BB             Walks\n",
      "#18 SO             Strikeouts\n",
      "#19 BAOpp          Opponent's Batting Average\n",
      "#20 ERA            Earned Run Average\n",
      "#21 IBB            Intentional Walks\n",
      "#22 WP             Wild Pitches\n",
      "#23 HBP            Batters Hit By Pitch\n",
      "#24 BK             Balks\n",
      "#25 BFP            Batters faced by Pitcher\n",
      "#26 GF             Games Finished\n",
      "#27 R              Runs Allowed\n",
      "#28 SH             Sacrifices by opposing batters\n",
      "#29 SF             Sacrifice flies by opposing batters\n",
      "#30 GIDP           Grounded into double plays by opposing batter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fielding stats\n",
      "# playerID       Player ID code\n",
      "# yearID         Year\n",
      "# stint          player's stint (order of appearances within a season)\n",
      "# teamID         Team\n",
      "# lgID           League\n",
      "# Pos            Position\n",
      "# G              Games \n",
      "# GS             Games Started\n",
      "# InnOuts        Time played in the field expressed as outs \n",
      "# PO             Putouts\n",
      "# A              Assists\n",
      "# E              Errors\n",
      "# DP             Double Plays\n",
      "# PB             Passed Balls (by catchers)\n",
      "# WP             Wild Pitches (by catchers)\n",
      "# SB             Opponent Stolen Bases (by catchers)\n",
      "# CS             Opponents Caught Stealing (by catchers)\n",
      "# ZR             Zone Rating"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Combines features from the pitching data into our existing data.\n",
      "# Note: Patrick had a nice way of doing this in class today with 'merge' ([much] faster!)\n",
      "# He also dropped a bunch of pitching data that appears in the existing data but \n",
      "# when I wrote this I didn't know if those features meant the same thing for \n",
      "# batters vs. pitchers?\n",
      "\n",
      "def add_pitching(df_in):\n",
      "    df_pitching = pd.read_csv('Pitching.csv')\n",
      "    df_pitching = df_pitching[df_pitching.yearID >= min(df_in.yearID)]\n",
      "    count = 0\n",
      "    # Add new blank columns for all added pitching data\n",
      "    zero_list = np.zeros([df_in.shape[0]]) \n",
      "    pitching_features = ['W', 'L', 'G', 'GS', 'CG', 'SHO', 'SV', 'IPouts', 'H', 'ER', 'HR', 'BB', 'SO', 'ERA', 'WP', 'HBP', 'BK', 'BFP', 'GF', 'R']\n",
      "    # All pitching features append 'p' out the front\n",
      "    for feature in pitching_features:\n",
      "        new_str = 'p'+feature\n",
      "        df_in[new_str] = zero_list    \n",
      "    for row in df_in.iterrows():     \n",
      "        cur_playerID = row[1].playerID\n",
      "        cur_year = row[1].yearID\n",
      "        row_lookup = (df_pitching.playerID == cur_playerID) & (df_pitching.yearID == cur_year)\n",
      "        for feature in pitching_features:\n",
      "            cur_val = df_pitching.loc[row_lookup,feature].values\n",
      "            if len(cur_val)>0:\n",
      "                cur_val = cur_val[0]\n",
      "            else:\n",
      "                # Set missing data here to zero. Is this reasonable?\n",
      "                cur_val = 0.0\n",
      "            new_str = 'p'+feature\n",
      "            df_in.ix[count,new_str] = cur_val\n",
      "        count +=1\n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Combines features from the fielding data into our existing data.\n",
      "\n",
      "def add_fielding(df_in):\n",
      "    df_fielding = pd.read_csv('Fielding.csv')\n",
      "    df_fielding = df_fielding[df_fielding.yearID >= min(df_in.yearID)]\n",
      "    count = 0\n",
      "    # Add new blank columns for all added fielding data\n",
      "    zero_list = np.zeros([df_in.shape[0]]) \n",
      "    fielding_features = ['PO', 'A', 'E', 'InnOuts']\n",
      "    # All fielding features append 'p' out the front\n",
      "    for feature in fielding_features:\n",
      "        new_str = 'f'+feature\n",
      "        df_in[new_str] = zero_list    \n",
      "    for row in df_in.iterrows():     \n",
      "        cur_playerID = row[1].playerID\n",
      "        cur_year = row[1].yearID\n",
      "        row_lookup = (df_fielding.playerID == cur_playerID) & (df_fielding.yearID == cur_year)\n",
      "        for feature in fielding_features:\n",
      "            cur_val = df_fielding.loc[row_lookup,feature].values\n",
      "            if len(cur_val)>0:\n",
      "                cur_val = cur_val[0]\n",
      "            else:\n",
      "                # Set missing data here to zero. Is this reasonable?\n",
      "                cur_val = 0.0\n",
      "            new_str = 'f'+feature\n",
      "            df_in.ix[count,new_str] = cur_val\n",
      "        count +=1\n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if fresh == 1:\n",
      "    df = add_pitching(df)\n",
      "    df = add_fielding(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if fresh ==1:\n",
      "    # Replace HOFID with binary 0 no, 1 yes\n",
      "    df['hofID'].fillna(0.0,inplace=True)\n",
      "    df.loc[df['hofID'] != 0.0,'hofID'] = 1.0\n",
      "    # Replace nickname with binary\n",
      "    df['nameNick'].fillna(0.0,inplace=True)\n",
      "    df.loc[df['nameNick'] != 0.0,'nameNick'] = 1.0\n",
      "    # Replace throws and bats L = 0, R = 1\n",
      "    df.loc[df['bats'] =='L','bats'] = 0.0\n",
      "    df.loc[df['bats'] =='R','bats'] = 1.0\n",
      "    df.loc[df['bats'] =='B','bats'] = 2.0\n",
      "    df.loc[df['throws'] =='L','throws'] = 0.0\n",
      "    df.loc[df['throws'] =='R','throws'] = 1.0\n",
      "    # Delete weird data\n",
      "    df = df[df.salary > 1]\n",
      "    df = df[df.yearID > 1]\n",
      "    df = df[df.weight > 2]\n",
      "    df = df[df.height > 2]\n",
      "    df = df.drop(['birthDate','bbrefID','college','nameGiven','birthCity','birthState','birthCountry','debut','finalGame','managerID','deathYear','deathMonth','deathCountry','deathState','deathDate','deathDay', 'lahman40ID', 'lahman45ID', 'retroID', 'holtzID','deathCity','nameFirst','nameLast','nameNote','G_old','lahmanID'],axis=1)\n",
      "    # Set remaning NaN stats to zero\n",
      "    # Based on assumption that the missing data is missing batting data from pitchers\n",
      "    # Can this be improved? Should we just delete it\n",
      "    for feature in df.columns:\n",
      "        null_mask = pd.isnull(df[feature])\n",
      "        # If they are missing batting data, but pitching data exists...\n",
      "        if feature not in ['fPO', 'fA', 'fE', 'fInnOuts']:\n",
      "            df.loc[(null_mask)& df.pERA!=0,feature] = 0.0\n",
      "        else:\n",
      "        # If they are missing fielding data, but batting or pitching data exists...\n",
      "            df.loc[(null_mask)& df.pERA!=0,feature] = 0.0\n",
      "            df.loc[(null_mask)& df.AB!=0,feature] = 0.0\n",
      "    # Remove few remaining NaNs    \n",
      "    df.dropna(how='any',inplace=True)\n",
      "\n",
      "    # Add in age\n",
      "    df['age'] = df['yearID']-df['birthYear']\n",
      "    # Add in batting ratio -> 0 pitchers, 1 batters\n",
      "    df['Batting_ratio']=df.G_batting/df.G\n",
      "    # Sort for cumulative stats below\n",
      "    df = df.sort(columns=['playerID','yearID'])\n",
      "    df.index = range(0,len(df))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_pitching_stats(df_in):\n",
      "    # Walks and hits per innings\n",
      "    df_in['pWHIP'] = 3.0*(df_in['pH'] + df_in['pBB'])/df_in['pIPouts']\n",
      "    null_mask = pd.isnull(df_in['pWHIP'])\n",
      "    df_in.loc[null_mask,'pWHIP'] = 0.0\n",
      "    \n",
      "    # Winning percentage\n",
      "    df_in['pWP'] = df_in['pW']/(df_in['pW'] + df_in['pL'])\n",
      "    null_mask = pd.isnull(df_in['pWP'])\n",
      "    df_in.loc[null_mask,'pWP'] = 0.0\n",
      "    \n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_offensive_stats(df_in):\n",
      "\n",
      "    # Total base percentage\n",
      "    df_in['TBP'] = (df_in['H']+df_in['BB']+df_in['HBP'])/(df_in['AB']+df_in['BB'] + df_in['HBP'])\n",
      "    null_mask = pd.isnull(df_in['TBP'])\n",
      "    df_in.loc[null_mask,'TBP'] = 0.0    \n",
      "    \n",
      "    # Plate appearance\n",
      "    df_in['PA'] = (df_in['AB']+df_in['BB']+df_in['HBP'] +df_in['SH']+df_in['SF'])\n",
      "    null_mask = pd.isnull(df_in['PA'])\n",
      "    df_in.loc[null_mask,'PA'] = 0.0\n",
      "    \n",
      "    # Total bases\n",
      "    df_in['TB'] = (df_in['H']+2.0*df_in['X2B']+3.0*df_in['X3B'] +4.0*df_in['HR'])\n",
      "    null_mask = pd.isnull(df_in['TB'])\n",
      "    df_in.loc[null_mask,'TB'] = 0.0\n",
      "\n",
      "    # Batting average\n",
      "    df_in['AVG'] = (df_in['H'])/(df_in['AB'])\n",
      "    null_mask = pd.isnull(df_in['AVG'])\n",
      "    df_in.loc[null_mask,'AVG'] = 0.0\n",
      "    \n",
      "    # Base on balls percentage\n",
      "    df_in['BOB'] = (df_in['BB'])/(df_in['PA'])\n",
      "    null_mask = pd.isnull(df_in['BOB'])\n",
      "    df_in.loc[null_mask,'BOB'] = 0.0    \n",
      "    \n",
      "    # Home run ratio\n",
      "    df_in['HRR'] = (df_in['HR'])/(df_in['AB'])\n",
      "    null_mask = pd.isnull(df_in['HRR'])\n",
      "    df_in.loc[null_mask,'HRR'] = 0.0     \n",
      "    \n",
      "    # On Base percentage\n",
      "    df_in['OBP'] = (df_in['H']+df_in['BB']+df_in['HBP'])/(df_in['AB'] +df_in['BB'] + df_in['HBP']+ df_in['SF'])\n",
      "    null_mask = pd.isnull(df_in['OBP'])\n",
      "    df_in.loc[null_mask,'OBP'] = 0.0  \n",
      "    \n",
      "    # Slugging average\n",
      "    df_in['SA'] = (df_in['TB'])/(df_in['AB'])\n",
      "    null_mask = pd.isnull(df_in['SA'])\n",
      "    df_in.loc[null_mask,'SA'] = 0.0\n",
      "    \n",
      "    # On Base Plus Slugging\n",
      "    df_in['OBPS'] = df_in['SA'] + df_in['OBP']\n",
      "    null_mask = pd.isnull(df_in['OBPS'])\n",
      "    df_in.loc[null_mask,'OBPS'] = 0.0  \n",
      "    \n",
      "    # Strike out ratio\n",
      "    df_in['SOR'] = (df_in['SO'])/(df_in['AB'])\n",
      "    null_mask = pd.isnull(df_in['SOR'])\n",
      "    df_in.loc[null_mask,'SOR'] = 0.0\n",
      "    \n",
      "    # Isolated power\n",
      "    df_in['ISO'] = (df_in['TB'] - df_in['H'])/(df_in['AB'])\n",
      "    null_mask = pd.isnull(df_in['ISO'])\n",
      "    df_in.loc[null_mask,'ISO'] = 0.0\n",
      "    \n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_defensive_stats(df_in):\n",
      "    # Fielding Average\n",
      "    df_in['fFA'] = (df_in['fPO'] +df_in['fA'])/(df_in['fPO'] +df_in['fA'] + df_in['fE'])\n",
      "    null_mask = pd.isnull(df_in['fFA'])\n",
      "    df_in.loc[null_mask,'fFA'] = 0.0\n",
      "    \n",
      "    # Range Factor\n",
      "    df_in['fRF'] = 9.0*(df_in['fPO'] +df_in['fA'])/df_in['fInnOuts']\n",
      "    null_mask = pd.isnull(df_in['fRF'])\n",
      "    df_in.loc[null_mask,'fRF'] = 0.0\n",
      "    \n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if fresh == 1:\n",
      "    df = add_pitching_stats(df)\n",
      "    df = add_offensive_stats(df)\n",
      "    df = add_defensive_stats(df)\n",
      "    # A few divide by zero infs\n",
      "    df = df.replace(np.inf,0.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add in years with they have been with their current club\n",
      "# Must be sorted for this to work\n",
      "# This turns out to be a strong predicter!\n",
      "def add_ywc(df_in):\n",
      "    count = 0\n",
      "    df_in['ywc'] = np.zeros([df_in.shape[0]])\n",
      "    for row in df_in.iterrows():\n",
      "        if count == 0:\n",
      "            df_in.ix[count,'ywc'] = 1\n",
      "            prev_playerID = row[1].playerID\n",
      "            prev_team = row[1].teamID\n",
      "            prev_year = row[1].yearID\n",
      "        else:            \n",
      "            cur_playerID = row[1].playerID\n",
      "            cur_team = row[1].teamID\n",
      "            cur_year = row[1].yearID\n",
      "            if cur_playerID == prev_playerID and cur_team == prev_team and cur_year == prev_year+1:\n",
      "                df_in.ix[count,'ywc'] = df_in.ix[count-1,'ywc'] + 1\n",
      "                prev_year = cur_year\n",
      "            else:\n",
      "                df_in.ix[count,'ywc'] = 1\n",
      "                prev_playerID = cur_playerID\n",
      "                prev_team = cur_team\n",
      "                prev_year = cur_year\n",
      "        \n",
      "        count += 1\n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add in years with club\n",
      "if fresh == 1:\n",
      "    df = add_ywc(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try cumulative stats over their careers\n",
      "def add_cum_stats(df_in):\n",
      "    \n",
      "    zero_list = np.zeros([df_in.shape[0]]) \n",
      "    features= ['G', 'G_batting', 'AB', 'R', 'H', 'X2B', 'X3B', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'IBB', 'HBP', 'SH', 'SF', 'GIDP', 'salary', 'pW', 'pL', 'pG', 'pGS', 'pCG', 'pSHO', 'pSV', 'pIPouts', 'pH', 'pER', 'pHR', 'pBB', 'pSO', 'pERA', 'pWP', 'pHBP', 'pBK', 'pBFP', 'pGF', 'pR', 'fPO', 'fA', 'fE', 'fInnOuts', 'pWHIP', 'fFA', 'fRF', 'TBP', 'PA', 'TB', 'AVG', 'BOB', 'HRR', 'OBP', 'SA', 'OBPS', 'SOR', 'ISO']  \n",
      "    for feature in features:\n",
      "        new_str = feature + '_cum'\n",
      "        df_in[new_str] = zero_list\n",
      "\n",
      "    count = 0\n",
      "    cur_playerID = ''   \n",
      "    for row in df_in.iterrows(): \n",
      "        if row[1].playerID == cur_playerID:\n",
      "            \n",
      "            for feature in features:\n",
      "                new_str = feature + '_cum'\n",
      "                df_in.ix[count,new_str] = df_in.ix[count-1,new_str] + df_in.ix[count,feature] \n",
      "        else:\n",
      "            for feature in features:\n",
      "                new_str = feature + '_cum'\n",
      "                df_in.ix[count,new_str] = df_in.ix[count,feature] \n",
      "            cur_playerID = row[1].playerID\n",
      "        count += 1 \n",
      "    # Log all this cumulative data\n",
      "    for feature in features:\n",
      "        new_str = feature + '_cum'\n",
      "        df_in[new_str] = np.log(1.0+df_in[new_str])\n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add in cumulative stats\n",
      "if fresh == 1:\n",
      "    df = add_cum_stats(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ranking of the teams based on some analysis Lema did\n",
      "# Should this be replaced with rankings 1-35?\n",
      "# The NYA appear to be way out in front of their neighbours\n",
      "# Should we just collapse this to a binary is_NYA variable?\n",
      "def replace_teams(df_in):\n",
      "    df_in['teamID_ranking'] = df_in['teamID']\n",
      "    df_in['is_NYA'] = df_in['teamID']\n",
      "    \n",
      "    pay_dict = {'TBA':0.563012316,\n",
      "    'FLO':0.590202151,\n",
      "    'WAS':0.628968556,\n",
      "    'MON':0.640852974,\n",
      "    'PIT':0.644590508,\n",
      "    'MIL':0.765931924,\n",
      "    'SDN':0.810817752,\n",
      "    'ML4':0.821061606,\n",
      "    'OAK':0.830736393,\n",
      "    'MIN':0.851800958,\n",
      "    'KCA':0.855405149,\n",
      "    'CLE':0.864584478,\n",
      "    'CIN':0.895130092,\n",
      "    'COL':0.900445365,\n",
      "    'ARI':0.949687104,\n",
      "    'HOU':0.985782018,\n",
      "    'ANA':0.992457703,\n",
      "    'SEA':0.993221428,\n",
      "    'TEX':0.996291621,\n",
      "    'CAL':1.020107846,\n",
      "    'CHA':1.029691571,\n",
      "    'BAL':1.030425975,\n",
      "    'PHI':1.031248116,\n",
      "    'DET':1.037312589,\n",
      "    'TOR':1.037545033,\n",
      "    'SLN':1.066267649,\n",
      "    'SFN':1.076192579,\n",
      "    'CHN':1.173932516,\n",
      "    'ATL':1.213932799,\n",
      "    'LAN':1.250521203,\n",
      "    'MIA':1.258127264,\n",
      "    'NYN':1.307755738,\n",
      "    'LAA':1.317793839,\n",
      "    'BOS':1.388804819,\n",
      "    'NYA':1.814579156}\n",
      "    rank_dict = {'TBA':1,\n",
      "    'FLO':2,\n",
      "    'WAS':3,\n",
      "    'MON':4,\n",
      "    'PIT':5,\n",
      "    'MIL':6,\n",
      "    'SDN':7,\n",
      "    'ML4':8,\n",
      "    'OAK':9,\n",
      "    'MIN':10,\n",
      "    'KCA':11,\n",
      "    'CLE':12,\n",
      "    'CIN':13,\n",
      "    'COL':14,\n",
      "    'ARI':15,\n",
      "    'HOU':16,\n",
      "    'ANA':17,\n",
      "    'SEA':18,\n",
      "    'TEX':19,\n",
      "    'CAL':20,\n",
      "    'CHA':21,\n",
      "    'BAL':22,\n",
      "    'PHI':23,\n",
      "    'DET':24,\n",
      "    'TOR':25,\n",
      "    'SLN':26,\n",
      "    'SFN':27,\n",
      "    'CHN':28,\n",
      "    'ATL':29,\n",
      "    'LAN':30,\n",
      "    'MIA':31,\n",
      "    'NYN':32,\n",
      "    'LAA':33,\n",
      "    'BOS':34,\n",
      "    'NYA':35}   \n",
      "    for team in pay_dict.keys():\n",
      "        df_in.teamID.replace(to_replace=team,value=pay_dict[team],inplace=True)\n",
      "        df_in.teamID_ranking.replace(to_replace=team,value=rank_dict[team],inplace=True)\n",
      "        if team != 'NYA':\n",
      "            df_in.is_NYA.replace(to_replace=team,value=0.0,inplace=True)\n",
      "        else:\n",
      "            df_in.is_NYA.replace(to_replace=team,value=1.0,inplace=True)\n",
      "    return df_in "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Replace teams with rankings\n",
      "if fresh == 1:\n",
      "    df = replace_teams(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Log of the stats\n",
      "def log_stats(df_in):\n",
      "    df_in['log_ywc'] = np.log(df_in.ywc)\n",
      "    df_in['log_salary'] = np.log(df_in.salary)\n",
      "    # Appy to all batting / pitching stats\n",
      "    features= ['G', 'G_batting', 'AB', 'R', 'H', 'X2B', 'X3B', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'IBB', 'HBP', 'SH', 'SF', 'GIDP', 'salary', 'pW', 'pL', 'pG', 'pGS', 'pCG', 'pSHO', 'pSV', 'pIPouts', 'pH', 'pER', 'pHR', 'pBB', 'pSO', 'pERA', 'pWP', 'pHBP', 'pBK', 'pBFP', 'pGF', 'pR', 'fPO', 'fA', 'fE', 'fInnOuts', 'pWHIP', 'fFA', 'fRF', 'TBP', 'PA', 'TB', 'AVG', 'BOB', 'HRR', 'OBP', 'SA', 'OBPS', 'SOR', 'ISO']  \n",
      "    for feature in features:\n",
      "        new_str = 'log_' + feature\n",
      "        df_in[new_str] = np.log(1.0+df_in[feature])\n",
      "    return df_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Log of stats\n",
      "if fresh == 1:\n",
      "    df = log_stats(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fix object types\n",
      "df.nameNick = df.nameNick.astype(float)\n",
      "df.throws = df.throws.astype(float)\n",
      "df.bats = df.bats.astype(float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-86-138141ffb2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fix object types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnameNick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnameNick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if fresh == 1:\n",
      "    df.to_pickle('df_baseball.pkl')\n",
      "\n",
      "# Something we were looking at today in class on Tuseday\n",
      "# Might indicate which features are useful\n",
      "corr_series = df.corr().ix[:,'log_salary']\n",
      "for indx,row in corr_series.iteritems():\n",
      "    print indx, row\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-87-cab0396acb81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Something we were looking at today in class on Tuseday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Might indicate which features are useful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcorr_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'log_salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorr_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mindx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Mean absolute error is our metric\n",
      "def mape(y_pred,y_true): \n",
      "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import PolynomialFeatures, scale\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
      "from sklearn.decomposition import PCA\n",
      "from itertools import combinations\n",
      "from scipy.misc import comb \n",
      "# from sklearn import svm\n",
      "\n",
      "# All the features at our disposal\n",
      "# features = ['birthMonth', 'nameNick', 'weight', 'height', 'bats', 'throws', 'yearID', \n",
      "# 'teamID', 'G', 'G_batting', 'AB', 'R', 'H', 'X2B', 'X3B', 'HR', 'RBI', 'SB',\n",
      "# 'CS', 'BB', 'SO', 'IBB', 'HBP', 'SH', 'SF', 'GIDP', 'pW', 'pL', 'pG', \n",
      "# 'pGS', 'pCG', 'pSHO', 'pSV', 'pIPouts', 'pH', 'pER', 'pHR', 'pBB', 'pSO', 'pERA', \n",
      "# 'pWP', 'pHBP', 'pBK', 'pBFP', 'pGF', 'pR', 'fPO', 'fA', 'fE', 'fInnOuts', 'age', \n",
      "# 'Batting_ratio', 'pWHIP', 'TBP', 'PA', 'TB', 'AVG', 'BOB', 'HRR', 'OBP', 'SA', \n",
      "# 'OBPS', 'SOR', 'ISO', 'fFA', 'fRF', 'ywc', 'G_cum', 'G_batting_cum', 'AB_cum',\n",
      "# 'R_cum', 'H_cum', 'X2B_cum', 'X3B_cum', 'HR_cum', 'RBI_cum', 'SB_cum', 'CS_cum', \n",
      "# 'BB_cum', 'SO_cum', 'IBB_cum', 'HBP_cum', 'SH_cum', 'SF_cum', 'GIDP_cum', \n",
      "# 'pW_cum', 'pL_cum', 'pG_cum', 'pGS_cum', 'pCG_cum', 'pSHO_cum', \n",
      "# 'pSV_cum', 'pIPouts_cum', 'pH_cum', 'pER_cum', 'pHR_cum', 'pBB_cum', 'pSO_cum',\n",
      "# 'pERA_cum', 'pWP_cum', 'pHBP_cum', 'pBK_cum', 'pBFP_cum', 'pGF_cum', 'pR_cum', \n",
      "# 'fPO_cum', 'fA_cum', 'fE_cum', 'fInnOuts_cum', 'pWHIP_cum', 'fFA_cum', 'fRF_cum', \n",
      "# 'TBP_cum', 'PA_cum', 'TB_cum', 'AVG_cum', 'BOB_cum', 'HRR_cum', 'OBP_cum', 'SA_cum', \n",
      "# 'OBPS_cum', 'SOR_cum', 'ISO_cum', 'teamID_ranking', 'is_NYA', 'log_ywc', \n",
      "# 'log_G', 'log_G_batting', 'log_AB', 'log_R', 'log_H', 'log_X2B', 'log_X3B', 'log_HR', \n",
      "# 'log_RBI', 'log_SB', 'log_CS', 'log_BB', 'log_SO', 'log_IBB', 'log_HBP', 'log_SH', \n",
      "# 'log_SF', 'log_GIDP', 'log_pW', 'log_pL', 'log_pG', 'log_pGS', 'log_pCG', 'log_pSHO',\n",
      "# 'log_pSV', 'log_pIPouts', 'log_pH', 'log_pER', 'log_pHR', 'log_pBB', 'log_pSO', \n",
      "# 'log_pERA', 'log_pWP', 'log_pHBP', 'log_pBK', 'log_pBFP', 'log_pGF', 'log_pR',\n",
      "# 'log_fPO', 'log_fA', 'log_fE', 'log_fInnOuts', 'log_pWHIP', 'log_fFA', 'log_fRF',\n",
      "# 'log_TBP', 'log_PA', 'log_TB', 'log_AVG', 'log_BOB', 'log_HRR', 'log_OBP', 'log_SA', \n",
      "# 'log_OBPS', 'log_SOR', 'log_ISO']\n",
      "\n",
      "# We can search subsets to find which combos give good results\n",
      "# Old list\n",
      "# features = ['yearID','age', 'log_ywc','RBI_cum','R_cum','BB_cum','pSO_cum','SA_cum']\n",
      "\n",
      "# Growing ranked list on first pass\n",
      "# features = ['fFA_cum', 'G_cum', 'G_batting_cum','fInnOuts_cum', 'OBPS_cum', \n",
      "# 'OBP_cum','TBP_cum', 'AVG_cum','SA_cum','PA_cum','AB_cum','SO_cum',\n",
      "# 'TB_cum', 'X2B_cum','H_cum', 'R_cum', 'SF_cum','SOR_cum','BB_cum', 'RBI_cum',\n",
      "# 'log_ywc', 'ISO_cum','HR_cum','GIDP_cum','pSO_cum','fE_cum','HBP_cum','BOB_cum',\n",
      "# 'age','IBB_cum', 'X3B_cum','pIPouts_cum','pBFP_cum','pW_cum','yearID','pH_cum',\n",
      "# 'pHR_cum','pL_cum','pBB_cum','pER_cum','pR_cum','pWP_cum','fA_cum', 'pG_cum',\n",
      "# 'fRF_cum','pHBP_cum','CS_cum','fPO_cum','SH_cum','pWHIP_cum','pGS_cum',\n",
      "# 'SB_cum','pERA_cum','pSHO_cum','pCG_cum','pGF_cum','pSV_cum','pBK_cum','Batting_ratio',\n",
      "# 'nameNick','weight','bats','height', 'birthMonth','throws','is_NYA','teamID']\n",
      "\n",
      "features = ['fFA_cum', 'yearID', 'G_cum', 'PA_cum', 'log_ywc', 'age', 'HR_cum', 'pSV_cum', 'ISO_cum', 'pW_cum']\n",
      "\n",
      "# Set up polynomial of degree\n",
      "clf = linear_model.LinearRegression()\n",
      "degree = 3\n",
      "polynomial_features = PolynomialFeatures(degree=degree,include_bias=True)\n",
      "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
      "                         (\"classifier\", clf)])\n",
      "\n",
      "#     pipeline = svm.SVR(kernel='poly', degree=2)\n",
      "\n",
      "# You can use this code to search a subset of 'features' for the best 'n_features'\n",
      "best_mape = 1000\n",
      "best_mape_features = []\n",
      "n_features = 10\n",
      "total_comb = comb(len(features),n_features)\n",
      "print 'Combinations : ', total_comb\n",
      "\n",
      "count = 0\n",
      "for trial_features in combinations(features,n_features):\n",
      "    \n",
      "    X = df.ix[:,trial_features].values\n",
      "    y = df[['log_salary']].values\n",
      "# Do we need scaling?    \n",
      "#     X = scale(X)\n",
      "#     y = scale(y)\n",
      "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
      "    \n",
      "    # Train classifier\n",
      "    pipeline.fit(X_train, y_train)\n",
      "    \n",
      "    # Predict on test data\n",
      "    predict_y = pipeline.predict(X_test)\n",
      "\n",
      "    # Some metrics\n",
      "    cur_rsq = pipeline.score(X_test,y_test)\n",
      "    cur_mse = mean_squared_error((predict_y), (y_test))\n",
      "    cur_mae = mean_absolute_error((predict_y), (y_test))\n",
      "    cur_mape = mape(np.exp(predict_y),np.exp(y_test))\n",
      "    \n",
      "    # Use mean absolute error as our main metric\n",
      "    if cur_mape < best_mape:\n",
      "        best_R = cur_rsq\n",
      "        best_mse = cur_mse\n",
      "        best_mae = cur_mae\n",
      "        best_mape = cur_mape\n",
      "        best_mape_features = trial_features\n",
      "    count +=1\n",
      "    \n",
      "    # Update progress\n",
      "    if count%(np.round(total_comb/10))==0:\n",
      "        print count, ' of ', total_comb\n",
      "\n",
      "print 'Best Summary:  '\n",
      "print 'Features: ', best_mape_features\n",
      "print 'MAPE: ', best_mape \n",
      "print 'R^2: ', (best_R)\n",
      "print 'MSE: ', (best_mse)\n",
      "print 'MAE: ', (best_mae)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-89-018e29a7af5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrial_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Do we need scaling?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Combinations :  1.0\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot some scatter plots for our best feature combo\n",
      "X = df.ix[:,best_mape_features].values\n",
      "y = df[['log_salary']].values\n",
      "pipeline.fit(X, y)\n",
      "predict_y = pipeline.predict(X)\n",
      "f, axarr = plt.subplots(3, 3,figsize=(15,15))\n",
      "\n",
      "# Plot model against data\n",
      "# Note: labels are not accurate if the features change\n",
      "axarr[0, 0].scatter(X[:,0],y)\n",
      "axarr[0, 0].scatter(X[:,0],predict_y,color='r',alpha = 0.25)\n",
      "axarr[0, 0].set_ylabel('log(salary)')\n",
      "axarr[0, 0].set_xlabel('fFA_cum ')\n",
      "\n",
      "axarr[0, 1].scatter(X[:,1],y)\n",
      "axarr[0, 1].scatter(X[:,1],predict_y,color='r',alpha = 0.25)\n",
      "axarr[0, 1].set_ylabel('log(salary)')\n",
      "axarr[0, 1].set_xlabel('yearID')\n",
      "\n",
      "axarr[0, 2].scatter(X[:,2],y)\n",
      "axarr[0, 2].scatter(X[:,2],predict_y,color='r',alpha = 0.25)\n",
      "axarr[0, 2].set_ylabel('log(salary)')\n",
      "axarr[0, 2].set_xlabel('G_cum')\n",
      "\n",
      "axarr[1, 0].scatter(X[:,3],y)\n",
      "axarr[1, 0].scatter(X[:,3],predict_y,color='r',alpha = 0.25)\n",
      "axarr[1, 0].set_ylabel('log(salary)')\n",
      "axarr[1, 0].set_xlabel('PA_cum')\n",
      "\n",
      "axarr[1, 1].scatter(X[:,4],y)\n",
      "axarr[1, 1].scatter(X[:,4],predict_y,color='r',alpha = 0.25)\n",
      "axarr[1, 1].set_ylabel('log(salary)')\n",
      "axarr[1, 1].set_xlabel('log_ywc')\n",
      "\n",
      "axarr[1, 2].scatter(X[:,5],y)\n",
      "axarr[1, 2].scatter(X[:,5],predict_y,color='r',alpha = 0.25)\n",
      "axarr[1, 2].set_ylabel('log(salary)')\n",
      "axarr[1, 2].set_xlabel('age')\n",
      "\n",
      "axarr[2, 0].scatter(X[:,6],y)\n",
      "axarr[2, 0].scatter(X[:,6],predict_y,color='r',alpha = 0.25)\n",
      "axarr[2, 0].set_ylabel('log(salary)')\n",
      "axarr[2, 0].set_xlabel('HR_cum')\n",
      "\n",
      "axarr[2, 1].scatter(X[:,7],y)\n",
      "axarr[2, 1].scatter(X[:,7],predict_y,color='r',alpha = 0.25)\n",
      "axarr[2, 1].set_ylabel('log(salary)')\n",
      "axarr[2, 1].set_xlabel('pSV_cum')\n",
      "\n",
      "axarr[2, 2].scatter(X[:,8],y)\n",
      "axarr[2, 2].scatter(X[:,8],predict_y,color='r',alpha = 0.25)\n",
      "axarr[2, 2].set_ylabel('log(salary)')\n",
      "axarr[2, 2].set_xlabel('ISO_cum')\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-90-6ff59ba53971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot some scatter plots for our best feature combo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_mape_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredict_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Is there any other plots or statistics we should look at from today's class?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For generating some result plots\n",
      "# x = np.arange(1,16)\n",
      "# mapes = np.array([104.379537106, 83.83813359,71.1490083069,57.0897741579,50.9621949766,49.400104754,48.3102080717,47.028007769,46.284537001,45.7685332902,45.3570336447,45.0696952697,44.8574298521,44.6964063211,44.7214473212])\n",
      "# rs = np.array([0.503669380356,0.618592637311,0.682667508573,0.795143211489,0.815535443476,0.823469850274,0.83219409585,0.841751365826,0.844870530072,0.846141145698,0.848899506203,0.849548284546,0.850310252798,0.850762392977,0.851051829388])\n",
      "# polys = [1,2,3,4,5]\n",
      "# poly_rs = [0.702565883731,0.819702297759,0.846141145698,0.847346260644,0.837764075993]\n",
      "# poly_mapes = [74.8684213379,52.1791714189,45.7685332902,44.8272028895,47.3292014557]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# font = {'family' : 'normal',\n",
      "#         'size'   : 12}\n",
      "\n",
      "# f, ax = plt.subplots()\n",
      "# ax.yaxis.label.set_size(14)\n",
      "# ax.xaxis.label.set_size(14)\n",
      "# plt.rc('font', **font)\n",
      "# ax.plot(polys,poly_rs)\n",
      "# ax.set_xlabel('Degree of polynomial')\n",
      "# ax.set_ylabel('R^2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}